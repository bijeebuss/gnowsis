services:
  # PostgreSQL with pgvector extension
  postgres:
    image: pgvector/pgvector:pg16
    container_name: tldr-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${DB_USER:-postgres}
      POSTGRES_PASSWORD: ${DB_PASSWORD:-postgres}
      POSTGRES_DB: ${DB_NAME:-tldr}
    volumes:
      - ./data/postgres:/var/lib/postgresql/data
    # ports:
    #   - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-postgres} -d ${DB_NAME:-tldr}"]
      interval: 5s
      timeout: 5s
      retries: 5

  # Temporal Server (using CLI)
  temporal:
    build:
      context: .
      dockerfile: temporal.dockerfile
    container_name: tldr-temporal
    restart: unless-stopped
    # ports:
    #   - "7233:7233"
    #   - "8233:8233"  # Temporal UI
    volumes:
      - ./data/temporal:/data
    healthcheck:
      test: ["CMD", "temporal", "workflow", "list", "--namespace", "default", "--address", "localhost:7233"]
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 30s

  # Application Server (API + Frontend)
  app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: tldr-app
    restart: unless-stopped
    command: >
      sh -c "npx prisma migrate deploy && npm run api"
    environment:
      DATABASE_URL: postgresql://${DB_USER:-postgres}:${DB_PASSWORD:-postgres}@postgres:5432/${DB_NAME:-tldr}?schema=public
      DB_HOST: postgres
      DB_PORT: "5432"
      DB_USER: ${DB_USER:-postgres}
      DB_PASSWORD: ${DB_PASSWORD:-postgres}
      DB_NAME: ${DB_NAME:-tldr}
      JWT_SECRET: ${JWT_SECRET}
      ENCRYPTION_SECRET: ${ENCRYPTION_SECRET}
      TEMPORAL_ADDRESS: temporal:7233
      GOTENBURG_URL: ${GOTENBURG_URL:-http://gotenberg:3000}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      OPENAI_API_ENDPOINT: ${OPENAI_API_ENDPOINT:-https://api.openai.com/v1}
      OPENAI_MODEL: ${OPENAI_MODEL:-gpt-4o-mini}
      PORT: "3000"
      NODE_ENV: ${NODE_ENV:-production}
    ports:
      - "${APP_PORT:-3000}:3000"
    volumes:
      - ./uploads:/app/uploads
    depends_on:
      postgres:
        condition: service_healthy
      temporal:
        condition: service_started

  # Combined Worker (Document + Email Processing)
  worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: tldr-worker
    restart: unless-stopped
    command: npm run combined-worker
    environment:
      DATABASE_URL: postgresql://${DB_USER:-postgres}:${DB_PASSWORD:-postgres}@postgres:5432/${DB_NAME:-tldr}?schema=public
      DB_HOST: postgres
      DB_PORT: "5432"
      DB_USER: ${DB_USER:-postgres}
      DB_PASSWORD: ${DB_PASSWORD:-postgres}
      DB_NAME: ${DB_NAME:-tldr}
      ENCRYPTION_SECRET: ${ENCRYPTION_SECRET}
      TEMPORAL_ADDRESS: temporal:7233
      GOTENBURG_URL: ${GOTENBURG_URL:-http://gotenberg:3000}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      OPENAI_API_ENDPOINT: ${OPENAI_API_ENDPOINT:-https://api.openai.com/v1}
      OPENAI_MODEL: ${OPENAI_MODEL:-gpt-4o-mini}
      NODE_ENV: ${NODE_ENV:-production}
    volumes:
      - ./uploads:/app/uploads
    depends_on:
      postgres:
        condition: service_healthy
      temporal:
        condition: service_started

  # Gotenberg - PDF conversion service (optional but recommended)
  gotenberg:
    image: gotenberg/gotenberg:8
    container_name: tldr-gotenberg
    restart: unless-stopped
    # ports:
    #   - "3003:3000"
    command:
      - "gotenberg"
      - "--api-timeout=120s"
      - "--libreoffice-disable-routes=true"
    profiles:
      - gotenberg
      - full

  # Ollama - Local LLM with GPU support (optional)
  ollama:
    image: ollama/ollama:latest
    container_name: tldr-ollama
    restart: unless-stopped
    # ports:
    #   - "11434:11434"
    volumes:
      - ./data/ollama:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    profiles:
      - ollama
      - full
